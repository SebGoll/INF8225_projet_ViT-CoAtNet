{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzMgs-YUsEXW"
   },
   "source": [
    "# Sources / Liens utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3wkazjpsHGO"
   },
   "source": [
    "**Article sur CoAtNet** : https://arxiv.org/pdf/2106.04803v2.pdf\n",
    "\n",
    "**Repo Github de l'architecture CoAtNet** : https://github.com/chinhsuanwu/coatnet-pytorch\n",
    "\n",
    "**Notebook de départ** : https://github.com/tyeso/Image_Classification_with_CoAtNet_and_ResNet18\n",
    "\n",
    "**Datasets accessibles par pytorch** : https://pytorch.org/vision/stable/datasets.html\n",
    "\n",
    "**Utilisation de ViT par Pytorch** : https://github.com/lucidrains/vit-pytorch#usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HT_kBKKHsNO0"
   },
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Zu2PzD_Br8Pi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision\n",
    "from torchvision import  transforms\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "\n",
    "import wandb\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWh81qdJsVbE",
    "outputId": "8f0a7400-92f8-423d-bdd4-ab74b7d462c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('using device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bj3jA1JRsZs9"
   },
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_mElwqDtRs2"
   },
   "source": [
    "Première partie : pipeline de transformation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "04vQsJ-asbIV"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784]),\n",
    "    ]\n",
    ")\n",
    "# For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop((32, 32), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv0c-fjjtceY"
   },
   "source": [
    "Deuxième partie : loading des données\n",
    "\n",
    "J'utilise ici le dataset de CIFAR10 pour que ce soit plus rapide pour les tests. On pourra voir si à un moment on a le temps pour tester sur d'autres datasets un peu plus gros. NB : dans CIFAR10, les images ont une taille 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_nqWpi3tfxn",
    "outputId": "6f7720ad-f76f-4e18-87f7-25dc2481b3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"/content/sample_data/\" #A changer si vous n'utilisez pas colab\n",
    "\n",
    "train_dataset = CIFAR100(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
    "val_dataset = CIFAR100(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
    "\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
    "\n",
    "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XWa0SO5HuJHx"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "Gc5XfOgLu5Zf",
    "outputId": "3b5966b2-bd91-46bf-e494-59980f2aefb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some examples\n",
    "NUM_IMAGES = 4\n",
    "CIFAR_images = torch.stack([val_set[idx][0] for idx in range(NUM_IMAGES)], dim=0)\n",
    "img_grid = torchvision.utils.make_grid(CIFAR_images, nrow=4, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Image examples of the CIFAR10 dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5CcxySfxDwL"
   },
   "source": [
    "# Train ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl4VS2MvFXw9"
   },
   "source": [
    "Les valeurs pour le modèle de ViT ont pour l'instant été un peu prises au hasard (à part image_size), ça fait partie des points à améliorer dans la recherche des hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mO7wClsYDm-8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "===========================================================================\nLayer (type:depth-idx)                             Param #\n===========================================================================\nViT                                                1,536\n├─Sequential: 1-1                                  --\n│    └─Rearrange: 2-1                              --\n│    └─LayerNorm: 2-2                              1,536\n│    └─Linear: 2-3                                 196,864\n│    └─LayerNorm: 2-4                              512\n├─Dropout: 1-2                                     --\n├─Transformer: 1-3                                 --\n│    └─ModuleList: 2-5                             --\n│    │    └─ModuleList: 3-1                        920,064\n│    │    └─ModuleList: 3-2                        920,064\n├─Identity: 1-4                                    --\n├─Sequential: 1-5                                  --\n│    └─LayerNorm: 2-6                              512\n│    └─Linear: 2-7                                 2,570\n===========================================================================\nTotal params: 2,043,658\nTrainable params: 2,043,658\nNon-trainable params: 0\n==========================================================================="
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vit_pytorch import ViT\n",
    "\n",
    "model = ViT(image_size = 32, patch_size = 16, num_classes = 10, dim = 256, depth = 2,\n",
    "            heads = 6, mlp_dim = 1024, dropout = 0.1, emb_dropout = 0.1)\n",
    "model = model.to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qFOasAv2vEmd"
   },
   "outputs": [],
   "source": [
    "def train_ViT(model, nb_epochs, gamma, lr):\n",
    "  # loss function\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  # optimizer\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "  # scheduler\n",
    "  scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "  for epoch in range(nb_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    progress_bar = tqdm(total=len(train_loader), position=0, leave=True)\n",
    "\n",
    "\n",
    "    for data, label in train_loader:\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == label).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "\n",
    "        progress_bar.update()\n",
    "    progress_bar.close()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, label in val_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(val_loader)\n",
    "            epoch_val_loss += val_loss / len(val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#train_ViT(model, nb_epochs = 10, gamma = 0.1, lr = 0.005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train CoAtNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nSaYaHMlCMYt"
   },
   "outputs": [],
   "source": [
    "# define configuration class\n",
    "class config:\n",
    "    img_size = (32, 32)\n",
    "    num_classes = 10\n",
    "    batch_size = 8\n",
    "    lr = 5e-3 \n",
    "    epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdnweFhgEuNp",
    "outputId": "ab1a8a60-7bea-4e61-f45c-9ce7162110e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SGoll\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": "================================================================================\nLayer (type:depth-idx)                                  Param #\n================================================================================\nCoAtNet                                                 --\n├─Sequential: 1-1                                       --\n│    └─Sequential: 2-1                                  --\n│    │    └─Conv2d: 3-1                                 864\n│    │    └─BatchNorm2d: 3-2                            64\n│    │    └─GELU: 3-3                                   --\n│    └─Sequential: 2-2                                  --\n│    │    └─Conv2d: 3-4                                 9,216\n│    │    └─BatchNorm2d: 3-5                            64\n│    │    └─GELU: 3-6                                   --\n├─Sequential: 1-2                                       --\n│    └─MBConv: 2-3                                      --\n│    │    └─MaxPool2d: 3-7                              --\n│    │    └─Conv2d: 3-8                                 2,048\n│    │    └─PreNorm: 3-9                                16,192\n│    └─MBConv: 2-4                                      --\n│    │    └─PreNorm: 3-10                               44,544\n├─Sequential: 1-3                                       --\n│    └─MBConv: 2-5                                      --\n│    │    └─MaxPool2d: 3-11                             --\n│    │    └─Conv2d: 3-12                                5,888\n│    │    └─PreNorm: 3-13                               51,768\n│    └─MBConv: 2-6                                      --\n│    │    └─PreNorm: 3-14                               89,792\n├─Sequential: 1-4                                       --\n│    └─Transformer: 2-7                                 --\n│    │    └─MaxPool2d: 3-15                             --\n│    │    └─MaxPool2d: 3-16                             --\n│    │    └─Conv2d: 3-17                                11,776\n│    │    └─Sequential: 3-18                            103,808\n│    │    └─Sequential: 3-19                            94,960\n│    └─Transformer: 2-8                                 --\n│    │    └─Sequential: 3-20                            131,528\n│    │    └─Sequential: 3-21                            131,968\n│    └─Transformer: 2-9                                 --\n│    │    └─Sequential: 3-22                            131,528\n│    │    └─Sequential: 3-23                            131,968\n├─Sequential: 1-5                                       --\n│    └─Transformer: 2-10                                --\n│    │    └─MaxPool2d: 3-24                             --\n│    │    └─MaxPool2d: 3-25                             --\n│    │    └─Conv2d: 3-26                                32,768\n│    │    └─Sequential: 3-27                            164,360\n│    │    └─Sequential: 3-28                            263,424\n│    └─Transformer: 2-11                                --\n│    │    └─Sequential: 3-29                            262,920\n│    │    └─Sequential: 3-30                            526,080\n├─AvgPool2d: 1-6                                        --\n├─Linear: 1-7                                           2,560\n================================================================================\nTotal params: 2,210,088\nTrainable params: 2,210,088\nNon-trainable params: 0\n================================================================================"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from coatnet import CoAtNet, coatnet_0\n",
    "#Penser à importer le fichier coatnet.py directement dans l'onglet fichier de colab\n",
    "\n",
    "#model = coatnet_3()\n",
    "num_blocks = [2, 2, 2, 3, 2]            # L\n",
    "channels = [32, 64, 92, 128, 256]    # D\n",
    "block_types=['C', 'C', 'T', 'T']         # 'C' for MBConv, 'T' for Transformer\n",
    "model = CoAtNet(config.img_size, 3, num_blocks, channels, block_types=block_types, num_classes = config.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMXIu9pXFruD"
   },
   "source": [
    "Ici, num_blocks correspond au nombre de fois qu'on va répéter l'opération dans un block. Par exemple, num_block[1] correspond à L1 dans le schéma d'explication p14 de l'article.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Oznul4jKV0OP"
   },
   "outputs": [],
   "source": [
    "def train_coatnet(model, nb_epochs, gamma, lr):\n",
    "  # loss function\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  # optimizer\n",
    "  optimizer = optim.SGD(model.fc.parameters(), lr=lr, momentum=0.9)\n",
    "  # scheduler\n",
    "  scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "  for epoch in range(nb_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    #for data, label in tqdm(train_loader):\n",
    "    for step, batch in enumerate(tqdm(train_loader)):\n",
    "        data, label = batch\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        #print(data.size())\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == label).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, label in val_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(val_loader)\n",
    "            epoch_val_loss += val_loss / len(val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "lJacTz12XLEG",
    "outputId": "9b713260-4ad9-4c35-ce4e-d7c6cbfefbf1"
   },
   "outputs": [],
   "source": [
    "#train_coatnet(model, nb_epochs = 10, gamma = 0.1, lr = 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD4jv-_2WLbX"
   },
   "source": [
    "# Recherche des meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5RT-gd0_-wj"
   },
   "source": [
    "Pour le ViT, les hyperparamètres sur lesquels on peut jouer sont : patch_size, dim, depth, heads, mlp_dim, dropout, emb_dropout\n",
    "\n",
    "Pour le CoAtNet, les hyperparamètres sur lesquels on peut jouer sont :  num_blocks, channels, block_types=block_types,\n",
    "\n",
    "Pour les deux : nombre d'épochs, lr, batch_size (peut être)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbtx2zn584Q9"
   },
   "source": [
    "Connexion à WandB + dictionnaire des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B_R4uu4GLGFP"
   },
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, loss_func, log_images=False, batch_idx=0):\n",
    "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, label) in enumerate(val_loader):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = loss_func(val_output, label)\n",
    "\n",
    "            _, predicted = torch.max(val_output.data, 1)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(val_loader)\n",
    "            epoch_val_loss += val_loss / len(val_loader)\n",
    "\n",
    "\n",
    "            # Log one batch of images to the dashboard, always same batch_idx.\n",
    "            if i==batch_idx and log_images:\n",
    "                log_image_table(data, predicted, label, val_output.softmax(dim=1))\n",
    "    return epoch_val_loss, epoch_val_accuracy\n",
    "\n",
    "def log_image_table(images, predicted, labels, probs):\n",
    "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
    "    # 🐝 Create a wandb Table to log images, labels and predictions to\n",
    "    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(10)])\n",
    "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
    "        table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n",
    "    wandb.log({\"predictions_table\":table}, commit=False)\n",
    "\n",
    "def train_model(model: nn.Module, config: dict):\n",
    "\n",
    "    train_loader, val_loader = config['train_loader'], config['val_loader']\n",
    "    train_dataset, val_dataset = train_loader.dataset.dataset, val_loader.dataset.dataset\n",
    "\n",
    "    optimizer = config['optimizer']\n",
    "    criterion = config[\"criterion\"]\n",
    "    scheduler = config[\"scheduler\"]\n",
    "\n",
    "    device = config['device']\n",
    "    n_steps_per_epoch = math.ceil(len(train_dataset) / config[\"batch_size\"])\n",
    "\n",
    "    example_ct = 0\n",
    "    step_ct = 0\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    print(f'Starting training for {config[\"epochs\"]} epochs, using {device}.')\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "\n",
    "        print(f'\\nEpoch {epoch+1}')\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "\n",
    "        progress_bar = tqdm(total=len(train_loader), position=0, leave=True)\n",
    "\n",
    "        for step, (data, label) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            train_loss = criterion(output, label)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == label).float().mean()\n",
    "\n",
    "            example_ct += len(data)\n",
    "            metrics = {\"train/train_loss\": train_loss,\n",
    "                       \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch,\n",
    "                       \"train/example_ct\": example_ct,\n",
    "                      \"train/accuracy\":acc}\n",
    "\n",
    "            if step + 1 < n_steps_per_epoch:\n",
    "                # 🐝 Log train metrics to wandb\n",
    "                wandb.log(metrics)\n",
    "            step_ct += 1\n",
    "\n",
    "            progress_bar.update()\n",
    "        progress_bar.close()\n",
    "\n",
    "        val_loss, accuracy = validate_model(model, val_loader, criterion, log_images=(epoch==(config['epochs']-1)))\n",
    "\n",
    "        val_metrics = {\"val/val_loss\": val_loss,\n",
    "                       \"val/val_accuracy\": accuracy}\n",
    "        wandb.log({**metrics, **val_metrics})\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "================================================================================\nLayer (type:depth-idx)                                  Param #\n================================================================================\nCoAtNet                                                 --\n├─Sequential: 1-1                                       --\n│    └─Sequential: 2-1                                  --\n│    │    └─Conv2d: 3-1                                 1,728\n│    │    └─BatchNorm2d: 3-2                            128\n│    │    └─GELU: 3-3                                   --\n│    └─Sequential: 2-2                                  --\n│    │    └─Conv2d: 3-4                                 36,864\n│    │    └─BatchNorm2d: 3-5                            128\n│    │    └─GELU: 3-6                                   --\n├─Sequential: 1-2                                       --\n│    └─MBConv: 2-3                                      --\n│    │    └─MaxPool2d: 3-7                              --\n│    │    └─Conv2d: 3-8                                 5,888\n│    │    └─PreNorm: 3-9                                51,768\n│    └─MBConv: 2-4                                      --\n│    │    └─PreNorm: 3-10                               89,792\n├─Sequential: 1-3                                       --\n│    └─MBConv: 2-5                                      --\n│    │    └─MaxPool2d: 3-11                             --\n│    │    └─Conv2d: 3-12                                16,744\n│    │    └─PreNorm: 3-13                               123,092\n│    └─MBConv: 2-6                                      --\n│    │    └─PreNorm: 3-14                               340,704\n│    └─MBConv: 2-7                                      --\n│    │    └─PreNorm: 3-15                               340,704\n├─Sequential: 1-4                                       --\n│    └─Transformer: 2-8                                 --\n│    │    └─MaxPool2d: 3-16                             --\n│    │    └─MaxPool2d: 3-17                             --\n│    │    └─Conv2d: 3-18                                46,592\n│    │    └─Sequential: 3-19                            206,004\n│    │    └─Sequential: 3-20                            374,232\n│    └─Transformer: 2-9                                 --\n│    │    └─Sequential: 3-21                            262,984\n│    │    └─Sequential: 3-22                            526,080\n│    └─Transformer: 2-10                                --\n│    │    └─Sequential: 3-23                            262,984\n│    │    └─Sequential: 3-24                            526,080\n│    └─Transformer: 2-11                                --\n│    │    └─Sequential: 3-25                            262,984\n│    │    └─Sequential: 3-26                            526,080\n├─Sequential: 1-5                                       --\n│    └─Transformer: 2-12                                --\n│    │    └─MaxPool2d: 3-27                             --\n│    │    └─MaxPool2d: 3-28                             --\n│    │    └─Conv2d: 3-29                                131,072\n│    │    └─Sequential: 3-30                            328,712\n│    │    └─Sequential: 3-31                            1,051,136\n│    └─Transformer: 2-13                                --\n│    │    └─Sequential: 3-32                            525,832\n│    │    └─Sequential: 3-33                            2,100,736\n├─AvgPool2d: 1-6                                        --\n├─Linear: 1-7                                           51,200\n================================================================================\nTotal params: 8,190,248\nTrainable params: 8,190,248\nNon-trainable params: 0\n================================================================================"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#config definition\n",
    "config = {\n",
    "    # General parameters\n",
    "    'epochs': 900,\n",
    "    'image_size' : 32,\n",
    "    'num_classes' : 100,\n",
    "    'batch_size': 16,\n",
    "    'lr': 2.5e-4,\n",
    "    'momentum' : 0.9,\n",
    "    'beta1' : 0.9,\n",
    "    'beta2':0.99,\n",
    "    'gamma_scheduler' : 0.1,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "\n",
    "    # ViT parameters model :\n",
    "    'dropout': 0.1,\n",
    "    'dim': 256,\n",
    "    'depth': 2,\n",
    "    'heads': 6,\n",
    "    'mlp_dim': 1024,\n",
    "    'emb_dropout': 0.1,\n",
    "\n",
    "    #CoAtNet parameters :\n",
    "    'in_channels': 3,\n",
    "    'num_blocks':  [2, 2, 3, 4, 2],      # L\n",
    "    'channels': [ 64, 92, 182, 256, 512],  # D\n",
    "    'block_types': ['C', 'C', 'T', 'T'],         # 'C' for MBConv, 'T' for Transformer\n",
    "\n",
    "    # Others\n",
    "    'seed': 0,\n",
    "    'log_every': 50,  # Number of batches between each wandb logs\n",
    "}\n",
    "\n",
    "torch.manual_seed(config['seed'])\n",
    "\n",
    "config['train_loader'] = train_loader\n",
    "\n",
    "config['val_loader'] = val_loader\n",
    "\n",
    "#Définition des modèles\n",
    "\"\"\"\n",
    "model = ViT(image_size = config['image_size'],\n",
    "            patch_size = config['batch_size'],\n",
    "            num_classes = config['num_classes'],\n",
    "            dim = config['dim'],\n",
    "            depth = config['depth'],\n",
    "            heads = config['heads'],\n",
    "            mlp_dim = config['mlp_dim'],\n",
    "            dropout = config['dropout'],\n",
    "            emb_dropout = config['emb_dropout'])\n",
    "\n",
    "\"\"\"\n",
    "model = CoAtNet(image_size = (config['image_size'], config['image_size']),\n",
    "                in_channels = config['in_channels'],\n",
    "                num_blocks = config['num_blocks'],\n",
    "                channels = config['channels'],\n",
    "                block_types=config['block_types'],\n",
    "                num_classes = config['num_classes'])\n",
    "#\"\"\"\n",
    "\n",
    "#Si le modèle est ViT\n",
    "config['optimizer'] = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    betas=(config['beta1'],config['beta2'])\n",
    ")\n",
    "\"\"\"\n",
    "#Si le modèle est CoAtNet\n",
    "\n",
    "config['optimizer'] = optim.SGD(\n",
    "  model.parameters(),\n",
    "  lr=config['lr'],\n",
    "  momentum=config['momentum']\n",
    ")\n",
    "#\"\"\"\n",
    "\n",
    "config[\"scheduler\"] = lr_scheduler.StepLR(\n",
    "    config['optimizer'],\n",
    "    step_size=1,\n",
    "    gamma=config['gamma_scheduler']\n",
    ")\n",
    "\n",
    "config['criterion'] = nn.CrossEntropyLoss()\n",
    "\n",
    "summary(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlZmLuibfn-V"
   },
   "source": [
    "Logging WandB\n",
    "\n",
    "You usually don't want to log anything onto WandB when testing your implementation.\n",
    "To deactivate WandB without having to change any line of code, you can type `!wandb offline` in a cell.\n",
    "\n",
    "Once you have rightly implemented the models, you can train bigger models on bigger datasets.\n",
    "When you do this, do not forget to change the runtime as GPU (and use `!wandb online`)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PL7vbqSCfqUu",
    "outputId": "b01126aa-88da-4e10-bf9b-6ab30cccaa0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: sebgoll (2231054-2229491). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B online. Running your script from this directory will now sync to the cloud.\n",
      "Sun Apr 30 15:58:08 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.41                 Driver Version: 531.41       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 L...  WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   41C    P8                8W /  N/A|   1751MiB /  4096MiB |      8%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1320    C+G   C:\\Program Files\\NordVPN\\NordVPN.exe      N/A      |\n",
      "|    0   N/A  N/A      2080    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A      3916    C+G   ...61.0_x64__8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A      4080    C+G   ...rm 2022.2.2\\jbr\\bin\\jcef_helper.exe    N/A      |\n",
      "|    0   N/A  N/A      4240    C+G   ...ocal\\Programs\\nordpass\\NordPass.exe    N/A      |\n",
      "|    0   N/A  N/A      4584    C+G   ...on\\wallpaper_engine\\wallpaper32.exe    N/A      |\n",
      "|    0   N/A  N/A      4764    C+G   ...03.0_x64__8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A      4864    C+G   ...on\\112.0.1722.64\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      9600    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10300    C+G   ...al\\Discord\\app-1.0.9012\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     10420      C   ...Programs\\Python\\Python39\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     12544    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     14992    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17464    C+G   ...nr4m\\radeonsoftware\\AMDRSSrcExt.exe    N/A      |\n",
      "|    0   N/A  N/A     18544    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     18856    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     18860    C+G   ...ft Office\\root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0   N/A  N/A     21676    C+G   ...m\\radeonsoftware\\RadeonSoftware.exe    N/A      |\n",
      "|    0   N/A  N/A     24208    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     25368    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     27404    C+G   ...on\\112.0.1722.64\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     29376    C+G   ...ft Office\\root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0   N/A  N/A     29660    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     30440    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Checking GPU and logging to wandb\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "!wandb login\n",
    "!wandb online\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b720f45b6f2f46e39d3c7eb706674bdf",
      "63e755aef3d54e14af25a233374036f1",
      "210f0db822a14f458c9cda0dda66c14a",
      "a59886aac4324ed585dc87e68dec831c",
      "f231bbcf1a1a4826a8574550dd55b9c2",
      "8ed9ec18045344de976f95f8985ddb41",
      "d19decc6ba4e477c8d070f727a985220",
      "d0b32cd4fab146478d338065f2b83d52"
     ]
    },
    "id": "aq_lvK0TgGvb",
    "outputId": "ebb11b7d-6202-4f9b-dadc-e8de350254c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: wandb online [OPTIONS]\n",
      "Try 'wandb online --help' for help.\n",
      "\n",
      "Error: Got unexpected extra arguments (# online / offline to activate or deactivate WandB logging)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.14.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\SGoll\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\wandb\\run-20230430_182940-v32vdv2m</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/2231054-2229491/INF8225-Projet/runs/v32vdv2m' target=\"_blank\">rosy-sun-84</a></strong> to <a href='https://wandb.ai/2231054-2229491/INF8225-Projet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/2231054-2229491/INF8225-Projet' target=\"_blank\">https://wandb.ai/2231054-2229491/INF8225-Projet</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/2231054-2229491/INF8225-Projet/runs/v32vdv2m' target=\"_blank\">https://wandb.ai/2231054-2229491/INF8225-Projet/runs/v32vdv2m</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 900 epochs, using cuda.\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.333, Valid Loss: 3.117165, Accuracy: 0.23\n",
      "\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.831, Valid Loss: 2.687036, Accuracy: 0.31\n",
      "\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.539, Valid Loss: 2.361688, Accuracy: 0.38\n",
      "\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.446, Valid Loss: 2.139534, Accuracy: 0.43\n",
      "\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.319, Valid Loss: 1.946608, Accuracy: 0.48\n",
      "\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.951, Valid Loss: 1.773258, Accuracy: 0.51\n",
      "\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.915, Valid Loss: 1.630418, Accuracy: 0.56\n",
      "\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.573, Valid Loss: 1.445612, Accuracy: 0.59\n",
      "\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.742, Valid Loss: 1.322030, Accuracy: 0.62\n",
      "\n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.316, Valid Loss: 1.234053, Accuracy: 0.66\n",
      "\n",
      "\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.284, Valid Loss: 1.071889, Accuracy: 0.71\n",
      "\n",
      "\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.172, Valid Loss: 0.974196, Accuracy: 0.72\n",
      "\n",
      "\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.175, Valid Loss: 0.903644, Accuracy: 0.75\n",
      "\n",
      "\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.963, Valid Loss: 0.833256, Accuracy: 0.77\n",
      "\n",
      "\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.805, Valid Loss: 0.702174, Accuracy: 0.80\n",
      "\n",
      "\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.767, Valid Loss: 0.645841, Accuracy: 0.82\n",
      "\n",
      "\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.817, Valid Loss: 0.637495, Accuracy: 0.82\n",
      "\n",
      "\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.656, Valid Loss: 0.578058, Accuracy: 0.84\n",
      "\n",
      "\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.416, Valid Loss: 0.487997, Accuracy: 0.87\n",
      "\n",
      "\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.657, Valid Loss: 0.478665, Accuracy: 0.87\n",
      "\n",
      "\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.595, Valid Loss: 0.474609, Accuracy: 0.87\n",
      "\n",
      "\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.303, Valid Loss: 0.443780, Accuracy: 0.89\n",
      "\n",
      "\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.695, Valid Loss: 0.419647, Accuracy: 0.89\n",
      "\n",
      "\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.405, Valid Loss: 0.406894, Accuracy: 0.90\n",
      "\n",
      "\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.604, Valid Loss: 0.394000, Accuracy: 0.90\n",
      "\n",
      "\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.457, Valid Loss: 0.427945, Accuracy: 0.89\n",
      "\n",
      "\n",
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.311, Valid Loss: 0.384120, Accuracy: 0.91\n",
      "\n",
      "\n",
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.211, Valid Loss: 0.406062, Accuracy: 0.91\n",
      "\n",
      "\n",
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.317, Valid Loss: 0.376908, Accuracy: 0.91\n",
      "\n",
      "\n",
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.266, Valid Loss: 0.371296, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.369, Valid Loss: 0.387204, Accuracy: 0.90\n",
      "\n",
      "\n",
      "Epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.213, Valid Loss: 0.390200, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.284, Valid Loss: 0.375798, Accuracy: 0.91\n",
      "\n",
      "\n",
      "Epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.303, Valid Loss: 0.360423, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:23<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.190, Valid Loss: 0.391759, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.234, Valid Loss: 0.387340, Accuracy: 0.91\n",
      "\n",
      "\n",
      "Epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.188, Valid Loss: 0.381184, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.128, Valid Loss: 0.370354, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.126, Valid Loss: 0.399399, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.269, Valid Loss: 0.387663, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.180, Valid Loss: 0.362801, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.182, Valid Loss: 0.392441, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.112, Valid Loss: 0.367162, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.309, Valid Loss: 0.401441, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.220, Valid Loss: 0.389088, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.221, Valid Loss: 0.409613, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.311, Valid Loss: 0.412879, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.165, Valid Loss: 0.411914, Accuracy: 0.92\n",
      "\n",
      "\n",
      "Epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.148, Valid Loss: 0.385469, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.190, Valid Loss: 0.374008, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.213, Valid Loss: 0.382694, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.174, Valid Loss: 0.382232, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.266, Valid Loss: 0.359772, Accuracy: 0.94\n",
      "\n",
      "\n",
      "Epoch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.123, Valid Loss: 0.361926, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.126, Valid Loss: 0.394509, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.281, Valid Loss: 0.400416, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.108, Valid Loss: 0.417450, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.096, Valid Loss: 0.398753, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.140, Valid Loss: 0.376524, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.112, Valid Loss: 0.390996, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.179, Valid Loss: 0.393586, Accuracy: 0.94\n",
      "\n",
      "\n",
      "Epoch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.202, Valid Loss: 0.418387, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.102, Valid Loss: 0.404044, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.187, Valid Loss: 0.400479, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.135, Valid Loss: 0.408363, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.065, Valid Loss: 0.396784, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.160, Valid Loss: 0.397389, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.138, Valid Loss: 0.391917, Accuracy: 0.94\n",
      "\n",
      "\n",
      "Epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.158, Valid Loss: 0.435675, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.185, Valid Loss: 0.415235, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.201, Valid Loss: 0.393127, Accuracy: 0.94\n",
      "\n",
      "\n",
      "Epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.080, Valid Loss: 0.430130, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:22<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.102, Valid Loss: 0.414328, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:23<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.046, Valid Loss: 0.421314, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:24<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.044, Valid Loss: 0.417151, Accuracy: 0.93\n",
      "\n",
      "\n",
      "Epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 163/351 [00:14<00:09, 19.50it/s]"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.188 MB of 0.188 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "610df8ef6ec84e44bcc87b791a8c4c24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇█▇▇▇██▇██████████████████</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/example_ct</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>█▆▅▅▄▃▃▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁▂▃▄▅▅▆▆▇▇▇▇████████████████████████████</td></tr><tr><td>val/val_loss</td><td>█▇▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>0.97656</td></tr><tr><td>train/epoch</td><td>75.05216</td></tr><tr><td>train/example_ct</td><td>3390464</td></tr><tr><td>train/train_loss</td><td>0.05018</td></tr><tr><td>val/val_accuracy</td><td>0.92891</td></tr><tr><td>val/val_loss</td><td>0.41715</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">rosy-sun-84</strong> at: <a href='https://wandb.ai/2231054-2229491/INF8225-Projet/runs/v32vdv2m' target=\"_blank\">https://wandb.ai/2231054-2229491/INF8225-Projet/runs/v32vdv2m</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230430_182940-v32vdv2m\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwandb online  # online / offline to activate or deactivate WandB logging\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m wandb\u001B[38;5;241m.\u001B[39minit(\n\u001B[0;32m      4\u001B[0m         config\u001B[38;5;241m=\u001B[39mconfig,\n\u001B[0;32m      5\u001B[0m         project\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINF8225-Projet\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Title of your project\u001B[39;00m\n\u001B[0;32m      6\u001B[0m         group\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOur_CoAtNet_L_100\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# In what group of runs do you want this run to be in?\u001B[39;00m\n\u001B[0;32m      7\u001B[0m         save_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m      8\u001B[0m     ):\n\u001B[1;32m----> 9\u001B[0m     \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[14], line 64\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, config)\u001B[0m\n\u001B[0;32m     61\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     62\u001B[0m label \u001B[38;5;241m=\u001B[39m label\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 64\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m criterion(output, label)\n\u001B[0;32m     66\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\coatnet.py:227\u001B[0m, in \u001B[0;36mCoAtNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    225\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms0(x)\n\u001B[0;32m    226\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms1(x)\n\u001B[1;32m--> 227\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ms2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms3(x)\n\u001B[0;32m    229\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms4(x)\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\coatnet.py:108\u001B[0m, in \u001B[0;36mMBConv.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproj(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(x)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(x)\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 108\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\coatnet.py:26\u001B[0m, in \u001B[0;36mPreNorm.forward\u001B[1;34m(self, x, **kwargs)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(x), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\INF8225 - Intelligence artificielle tech. prob. et d'apprentissage\\Projet\\venv\\lib\\site-packages\\torch\\nn\\modules\\activation.py:685\u001B[0m, in \u001B[0;36mGELU.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    684\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 685\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapproximate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapproximate\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "!wandb online  # online / offline to activate or deactivate WandB logging\n",
    "\n",
    "with wandb.init(\n",
    "        config=config,\n",
    "        project='INF8225-Projet',  # Title of your project\n",
    "        group='Our_CoAtNet_L_100',  # In what group of runs do you want this run to be in?\n",
    "        save_code=True,\n",
    "    ):\n",
    "    train_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "b720f45b6f2f46e39d3c7eb706674bdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63e755aef3d54e14af25a233374036f1",
       "IPY_MODEL_210f0db822a14f458c9cda0dda66c14a"
      ],
      "layout": "IPY_MODEL_a59886aac4324ed585dc87e68dec831c"
     }
    },
    "63e755aef3d54e14af25a233374036f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f231bbcf1a1a4826a8574550dd55b9c2",
      "placeholder": "​",
      "style": "IPY_MODEL_8ed9ec18045344de976f95f8985ddb41",
      "value": "0.303 MB of 0.303 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "210f0db822a14f458c9cda0dda66c14a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d19decc6ba4e477c8d070f727a985220",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0b32cd4fab146478d338065f2b83d52",
      "value": 1
     }
    },
    "a59886aac4324ed585dc87e68dec831c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f231bbcf1a1a4826a8574550dd55b9c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ed9ec18045344de976f95f8985ddb41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d19decc6ba4e477c8d070f727a985220": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0b32cd4fab146478d338065f2b83d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
